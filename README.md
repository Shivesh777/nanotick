# NanoTick

**ITCH-to-Parquet pipeline + ultra-low-latency limit-order-book (LOB) replay engine  
designed for *quant research* and *high-frequency trading* workflows on Apple Silicon & x86-64.**

| Component | Language | Throughput | Latency p99 | Lines |
|-----------|----------|-----------:|------------:|-------|
| ITCHâ†’Parquet | Python (Arrow) | 280 k msg/s | n/a | ~240 |
| LOB replay | Python + Numba | 0.20 M msg/s | 6958 ns | ~220 |
| LOB replay | C++20 | **4.27 M msg/s** | **6.6 ns** | ~180 |


> *Measured on an Apple M1 Air (8-core, 8 GB) with Apache Arrow,  
>  dataset: 30 283 409 BX ITCH 5.0 messages for 30 May 2019.*

---

## 1  TL;DR

* Converts raw **BX ITCH 5.0** feeds to **loss-free Parquet** in < 6 s with full schema + Zstd compression.  
* Replays an entire trading day (â‰ˆ 30 M msgs) into live LOBs in **7 s flat** (C++), tracking nanosecond-level latency.  
* Zero-copy Arrow buffers â†’ branch-free, pointer-free hot paths.  
* SIMD-friendly, cache-dense data layout; `-march=native -O3 -flto` for x86 & Apple Silicon.  
* Same schema + API across **Python (rapid prototyping)** and **C++ (production)**.

---


## 2  Quick Start

```bash
# 2.1  Get sample data  (~475 MB)
wget ftp://emi.nasdaq.com/ITCH/20190530.BX_ITCH_50.gz
mv 20190530.BX_ITCH_50.gz ../data/

# 2.2  Create env  (Py 3.13 supported)
conda create -n tick python=3.13
conda activate tick
pip install -r requirements.txt

# (macOS) Arrow C++ for the C++ engine
brew install apache-arrow             # or use your distroâ€™s package manager
````

---

## 3  ITCH âžœ Parquet Converter

```bash
python itch_to_parquet.py  \
       ../data/20190530.BX_ITCH_50.gz \
       bx_20190530.parquet
```

```
ðŸš€ Starting ITCHâ†’Parquet conversion...
Input : 20190530.BX_ITCH_50.gz
Output: bx_20190530.parquet
Parsing: 36 458 115 msg [02:10, 280 016 msg/s]
âœ“ Parquet write completed in 5.82 s
```

### Captured Schema

| column                   | type        | description                        |
| ------------------------ | ----------- | ---------------------------------- |
| `ts`                     | u64         | nanoseconds since midnight UTC     |
| `oid`                    | u64         | order reference-number             |
| `side`                   | u8          | 0 = bid, 1 = ask, 255 = N/A        |
| `px`                     | u32         | price Ã— 1e-4 USD                   |
| `qty`                    | u32         | shares / contracts                 |
| `m`                      | string      | message type (A,C,E,U,â€¦)           |
| `stock`                  | string      | ticker (symbol dictionary-encoded) |
| `new_oid,new_px,new_qty` | u64/u32/u32 | for *replace* (U) messages         |

**Why Parquet?**
*Columnar* + *compressed* + *random-seekable* â‡’ perfect for microstructure research, back-tests & ML feature generation.

---

## 4  Python LOB Replay Engine

```bash
python lob_replay.py bx_20190530.parquet
```

```
Loading Parquet file...
Processing 30 283 409 messages...

LOB Replay Metrics
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Rows processed     : 30 283 409
Total wall time    : 154.437 s
Throughput         : 0.20 M msg/s
Latency p50 / p95  : 5 708 ns / 6 416 ns
Order books created: 7 400
Symbols processed  : DWT, USO, KOLD, â€¦ (+7 390)
```

### Python optimisations

* **Numba JIT**: hot functions (`add/cancel/execute/replace`) compiled to LLVM.
* **PyArrow buffers**: zero-copy NumPy views, no Python object boxing.
* Typed `numba.Dict` for cache-friendly hash tables.
* High-resolution `perf_counter_ns()` for nano-latency profiles.

---

## 5  C++20 LOB Replay Engine

```bash
INC=$(brew --prefix)/include
LIB=$(brew --prefix)/lib
g++ -O3 -march=native -std=c++20 -flto \
    lob_replay.cpp -I${INC} -L${LIB} \
    -larrow -lparquet -pthread -o lob_replay

./lob_replay bx_20190530.parquet
```

```
LOB Replay Metrics
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Rows processed     : 30 283 409
Total wall time    : 7.084 s
Throughput         : 4.275 M msg/s
Latency (cycles)   : p50 2 | p95 14 | p99 21 | max 257 209
```

### C++ optimisations

* **Arrow C++**: direct `UInt32Array` / `StringArray` chunk pointers.
* **Branch-free** LOB operations, `unordered_map` pre-reserved.
* `__builtin_readcyclecounter()` for sub-nanosecond cycle timing.
* `-march=native -O3 -flto` + PGO ready; tested on AVX2 & Apple ARM v8.
* Single-threaded by design; easy to shard by `stock` for embarrassingly parallel replay.

---

## 6  Order-Book Logic (identical in Py & C++)

Message â†’ Action mapping:

| ITCH msg | Engine op                             | Complexity |
| -------- | ------------------------------------- | ---------: |
| A / F    | `add(oid,side,px,qty)`                |       O(1) |
| C / D    | `cancel(oid)`                         |       O(1) |
| E / X    | `execute(oid,qty_exec)`               |       O(1) |
| U        | `replace(oid,new_oid,new_px,new_qty)` |       O(1) |

Each symbol maintains:

```text
live_orders : oid â†’ {px,qty,side}
bid_size    : px  â†’ qty       (levels)
ask_size    : px  â†’ qty
```

All containers are *open-addressing* hash maps â‡’ constant-time updates and minimal cache miss.

---

## 8  Extending millitick

* **Sharding** â€“ split Parquet by `stock` and replay in parallel processes.
* **VWAP / depth snapshots** â€“ expose hooks inside LOB loop for real-time analytics.
* **Options / Futures** â€“ schema already supports contract IDs; add tick-size logic.
* **GPU acceleration** â€“ Arrow CUDA buffers drop in with minimal refactor.

---

## 9  License

MIT.  Use freely, cite if you like.

---

> *Built by Shivesh Prakash, drop a line at **shiveshprakash2@gmail.com** or connect on [LinkedIn](https://linkedin.com/in/Shivesh777).*
